{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96bb297",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from  langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605d7be0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "local_llm = \"gemma3n:e4b\"\n",
    "llm = ChatOllama(model=local_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d29147",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97e20ef-361a-400c-8ff6-879da13e303b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f67d5a7-4ff9-4334-a5ab-9d19ede2c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url = os.getenv(\"OLLAMA_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaa308f8-a2ee-4487-bbb2-5ccc46d1d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url = os.getenv(\"OLLAMA_BASE_URL\")\n",
    "llm_model = os.getenv(\"LLM_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86fd793d-457e-4758-bedb-0a281e327a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "print(ollama_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e441f90d-235d-4924-9fe1-229fd0f66e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(BaseModel):\n",
    "    agent_type: str = \"curation\"\n",
    "    topic: str\n",
    "    final_output: str = \"\"\n",
    "\n",
    "def generate_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Langgraph node that generates query\n",
    "    \"\"\"\n",
    "    ollama_url = os.getenv(\"OLLAMA_BASE_URL\")\n",
    "    llm_model = os.getenv(\"LLM_MODEL\")\n",
    "    chat_ollama = ChatOllama(\n",
    "            base_url=ollama_url, \n",
    "            model=llm_model, \n",
    "        )\n",
    "    user_message = HumanMessage(content=f\"Hello, what is {state.topic}?\")\n",
    "    result = chat_ollama.invoke([user_message])\n",
    "    state.final_output = result.content\n",
    "    return state\n",
    "    \n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "builder.add_edge(\"generate_query\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7007df59-8dc5-4d96-ba75-2d46e98ccb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_type': 'curation',\n",
       " 'topic': 'LLM',\n",
       " 'final_output': 'Hello! LLM stands for **Large Language Model**. \\n\\nHere\\'s a breakdown of what that means:\\n\\n*   **Language Model:** At its core, a language model is a computer program trained to understand and generate human language. It learns patterns in text – how words relate to each other, grammar rules, common phrases, and even different writing styles.\\n\\n*   **Large:** The \"large\" part refers to the massive size of these models. They are trained on incredibly huge datasets of text and code – often billions or even trillions of words. This massive scale is what allows them to learn complex language patterns and perform sophisticated tasks.\\n\\n**So, put together, a Large Language Model is a powerful AI that has been trained on a vast amount of text data to understand and generate human-like language.**\\n\\n**What can LLMs do?**\\n\\nLLMs are capable of a wide range of tasks, including:\\n\\n*   **Text generation:** Writing articles, stories, poems, scripts, and more.\\n*   **Translation:** Translating languages.\\n*   **Question answering:** Answering questions in a comprehensive and informative way.\\n*   **Summarization:** Condensing long pieces of text into shorter summaries.\\n*   **Code generation:** Writing computer code.\\n*   **Chatbots:** Powering conversational AI.\\n*   **Sentiment analysis:** Determining the emotional tone of text.\\n*   **Content creation:** Assisting with marketing copy, social media posts, etc.\\n*   **And much more!**\\n\\n**Examples of popular LLMs:**\\n\\n*   **GPT-3, GPT-4 (OpenAI):**  Very powerful and widely used.  Powers ChatGPT.\\n*   **LaMDA (Google):** Designed for conversational applications.\\n*   **Bard (Google):** Google\\'s conversational AI service, powered by LaMDA and other models.\\n*   **LLaMA (Meta):** An open-source LLM.\\n*   **Claude (Anthropic):**  Another powerful LLM focused on safety and helpfulness.\\n\\n\\n\\n**Key characteristics of LLMs:**\\n\\n*   **Transformer Architecture:**  Most modern LLMs are based on a neural network architecture called the \"transformer.\" This architecture is very effective at processing sequential data like text.\\n*   **Self-Attention:**  A key component of the transformer architecture that allows the model to weigh the importance of different words in a sentence when understanding or generating text.\\n*   **Pre-training and Fine-tuning:** LLMs are typically \"pre-trained\" on massive datasets and then \"fine-tuned\" on smaller, more specific datasets to improve their performance on particular tasks.\\n\\n\\n\\n**In simple terms:** Think of an LLM as a really smart computer program that has read a huge library of books, articles, and websites. Because it has read so much, it can understand and generate text that is remarkably similar to what a human would write.\\n\\n\\n\\nDo you have any other questions about LLMs? I\\'m happy to try and answer them!\\n\\n\\n\\n'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"topic\": \"LLM\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7fca9-313a-46e6-9309-98b0edcfd31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
